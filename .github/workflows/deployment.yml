name: deploy dbt project
# This filter says only run this job when there is a push to the main branch
# This works off the assumption that you've restricted this branch to only all PRs to push to the default branch
# Update the name to match the name of your default branch

on:
  push:
    branches:
      - 'main'

env:
  DBT_PRODUCTION_ARGS: --project-dir dags/dbt/jaffle_shop --profiles-dir dags/dbt/jaffle_shop --target prod

jobs:
  upload:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: setup python environment
        uses: actions/setup-python@v2
      - name: install python dependencies
        uses: py-actions/py-dependency-install@v4
        with:
          path: "ci-requirements.txt"
      - name: compile dbt manifest in production branch
        env:
          DBT_ACCESS_TOKEN: ${{ secrets.DBT_ACCESS_TOKEN }}
        run: |
          dbt deps ${{ env.DBT_PRODUCTION_ARGS }}
          dbt compile ${{ env.DBT_PRODUCTION_ARGS }}
      - uses: bacongobbler/azure-blob-storage-upload@main
        with:
          source_dir: dags
          container_name: airflow
          extra_args: '--destination-path dags'
          connection_string: ${{ secrets.BLOB_STORAGE_CONNECTION_STRING }}
          overwrite: 'true'
      - name: Set up Azure CLI
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}
          allow-no-subscriptions: true
      - name: Get Azure Service Principal Token
        id: get_token
        run: |
          az account set --subscription 0e769015-a299-41a6-9793-8ffebd94ca3b
          ACCESS_TOKEN=$(az account get-access-token --resource=https://management.azure.com --query accessToken -o tsv)
          echo "ACCESS_TOKEN=$ACCESS_TOKEN" >> $GITHUB_ENV
      - name: Call Sync REST API
        run: |
          API_ENDPOINT="https://management.azure.com/subscriptions/0e769015-a299-41a6-9793-8ffebd94ca3b/resourceGroups/rg-dataops3.0-dbt/providers/Microsoft.DataFactory/factories/dbt-dataops/airflow/sync?api-version=2018-06-01"

          REQUEST_DATA='{
            "IntegrationRuntimeName": "gopal-airflow",
            "LinkedServiceName": "airflowblobstoragelinkedservice",
            "StorageFolderPath": "airflow",
            "CopyFolderStructure": true,
            "Overwrite": true,
            "AddRequirementsFromFile": true
          }'

          RESPONSE_CODE=$(curl -s -o /dev/null -w "%{http_code}" -X POST -H "Authorization: Bearer $ACCESS_TOKEN" -H "Content-Type: application/json" -d "$REQUEST_DATA" $API_ENDPOINT)

          if [ $RESPONSE_CODE -eq 202 ]; then
            echo "API call was successful (202 response)"
          else
            echo "API call failed with response code $RESPONSE_CODE"
            exit 1  # Fail the workflow if the response code is not 202
          fi
